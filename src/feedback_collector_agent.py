# src/feedback_collector_agent.py

from typing import List
from typing import Optional
from src.create_llm_message import create_llm_message, create_llm_msg
from src.send_email import send_email
from src.prompt_store import get_prompt
from langchain_core.messages import BaseMessage
from pydantic import BaseModel

# When FeedbackCollectorAgent object is created, it's initialized with a client, a model, and an index. 
# The main entry point is the feedback_collector_agent method. You can see workflow.add_node for feedback_collector_agent 
# node in graph.py

# Define Pydantic models for structured output
class FeedbackResponse(BaseModel):
    response: str
    createFeedback: bool
    email: Optional[str]

class FeedbackEmail(BaseModel):
    response: str
    htmlEmail: str

class FeedbackCollectorAgent:
    
    def __init__(self, model):
        """
        Initialize the FeedbackCollectorAgent with necessary components.
        
        :param model: Language model for generating responses
        """
        self.model = model


    def generate_response(self, state: dict) -> str:
        """
        Generate a response based on user query.
        
        :param user_query: Original user query
        :return: Generated response string
        """
        user_query = state.get('initialMessage', '')
        
        # Get feedback collector prompt from prompt_store.py 
        feedback_collector_prompt = get_prompt("feedbackcollector").format(user_query=user_query)

        # Create a well-formatted message for LLM by passing the retrieved information above to create_llm_msg
        llm_messages = create_llm_msg(feedback_collector_prompt, state['message_history'])

        # Invoke the model with the well-formatted prompt, including SystemMessage, HumanMessage, and AIMessage
        llm_response = self.model.with_structured_output(FeedbackResponse).invoke(llm_messages)

        # Extract the content attribute from the llm_response object 
        feedback_collector_response = llm_response

        return feedback_collector_response
    
    def generate_feedback_email(self, state: dict) -> str:
        """
        Generate an email as a well-formatted html using the ChatOpenAI model.
        
        :param user_query: The original query from the user.
        :return: A string response generated by the language model.
        
        """

        # Get the prompt from prompt_store.py to generate email for the support team
        feedback_email_prompt = get_prompt("feedbackemail")

        # Create a well-formatted message for LLM by passing the retrieved information above to create_llm_msg
        llm_messages = create_llm_msg(feedback_email_prompt, state['message_history'])

        # Invoke the model with the well-formatted prompt, including SystemMessage, HumanMessage, and AIMessage
        llm_response = self.model.with_structured_output(FeedbackEmail).invoke(llm_messages)
        
        # Extract the content attribute from the llm_response object 
        feedback_email_response = llm_response.htmlEmail
        return feedback_email_response

    def feedback_collector_agent(self, state: dict) -> dict:
        """
        Main entry point for feedback related queries.
        
        :param state: Current state dictionary containing user's initial message
        :return: Updated state dictionary with generated response and category
        """
        
        # Generate a response using the retrieved documents and the user's initial message
        full_response = self.generate_response(state)

        if full_response.createFeedback:
            print("Generating and sending feedback email...")
            feedback_email_response = self.generate_feedback_email(state)
            
            print(f"Sending email to: i_jahangir@hotmail.com")
            send_email('malihajburney@gmail.com', 'i_jahangir@hotmail.com', "Feedback for Sales Comp", feedback_email_response)
        
        # Return the updated state with the generated response and the category set to 'policy'
        return {
            "lnode": "feedback_collector_agent", 
            "responseToUser": full_response.response,
            "category": "feedbackcollector"
        }
